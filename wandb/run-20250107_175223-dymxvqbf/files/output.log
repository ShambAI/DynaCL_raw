[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.

































































































































  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                            | 366/5797 [04:22<1:04:57,  1.39it/s]
Traceback (most recent call last):
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/RAW_DATA/baselines/vanilla_cl.py", line 344, in <module>
    dataset=test_dataset,
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/RAW_DATA/baselines/vanilla_cl.py", line 165, in main
    train_loss.backward()
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/wandb/wandb_torch.py", line 271, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
KeyboardInterrupt